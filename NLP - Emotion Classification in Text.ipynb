{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f96d94",
   "metadata": {},
   "source": [
    "## NLP - Emotion Classification in Text\n",
    "### Objective:\n",
    "Develop machine learning models to classify emotions in text samples.\n",
    "\n",
    "### 1. Loading and Preprocessing (3 marks)\n",
    "Load the dataset and perform necessary preprocessing steps. This should include text cleaning, tokenization, and removal of stopwords. Explain the preprocessing techniques used and their impact on model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc430a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b48cec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\91954\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\91954\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment Emotion\n",
      "0  i seriously hate one subject to death but now ...    fear\n",
      "1                 im so full of life i feel appalled   anger\n",
      "2  i sit here to write i start to dig out my feel...    fear\n",
      "3  ive been really angry with r and i feel like a...     joy\n",
      "4  i feel suspicious if there is no one outside l...    fear\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"nlp_dataset.csv\")\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46950a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for text cleaning\n",
    "def clean_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data['cleaned_comment'] = data['Comment'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12565c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment  \\\n",
      "0  i seriously hate one subject to death but now ...   \n",
      "1                 im so full of life i feel appalled   \n",
      "2  i sit here to write i start to dig out my feel...   \n",
      "3  ive been really angry with r and i feel like a...   \n",
      "4  i feel suspicious if there is no one outside l...   \n",
      "\n",
      "                                   processed_comment Emotion  \n",
      "0  seriously hate one subject death feel reluctan...    fear  \n",
      "1                         im full life feel appalled   anger  \n",
      "2  sit write start dig feelings think afraid acce...    fear  \n",
      "3  ive really angry r feel like idiot trusting fi...     joy  \n",
      "4  feel suspicious one outside like rapture happe...    fear  \n"
     ]
    }
   ],
   "source": [
    "# Tokenization and stopword removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['processed_comment'] = data['cleaned_comment'].apply(preprocess_text)\n",
    "\n",
    "# Display the processed comments\n",
    "print(data[['Comment', 'processed_comment', 'Emotion']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1909e",
   "metadata": {},
   "source": [
    "### Text Cleaning:\n",
    "It involves removing any irrelevant characters, such as punctuation and numbers, that do not contribute to the meaning of the text. This step also includes converting all text to lowercase to ensure uniformity, preventing the model from treating the same words in different cases as distinct (e.g., \"Happy\" vs. \"happy\"). By cleaning the text, we reduce complexity and focus on meaningful content, which helps improve the model's accuracy.\n",
    "\n",
    "### Tokenization:\n",
    "It breaks down the cleaned text into individual words or tokens. This process is crucial because it allows the model to analyze word frequencies and patterns more effectively. Tokenization can be performed using libraries like NLTK (Natural Language Toolkit), which provides tools for splitting sentences into words. By converting text into tokens, we create a structured format that machine learning algorithms can easily interpret, enabling them to learn from the data more efficiently.\n",
    "\n",
    "### Stopword Removal: Eliminates common words that do not add significant meaning, thus reducing noise.\n",
    "It eliminate common words (such as \"and,\" \"the,\" and \"is\") that do not carry significant meaning and can add noise to the analysis. Using predefined lists of stopwords from libraries like NLTK, we filter out these words from our tokenized text. This step is essential because it helps reduce the dimensionality of the dataset, allowing the model to focus on more meaningful words that contribute to emotional expression. Overall, these preprocessing techniques enhance the quality of input data, leading to improved performance of machine learning models in accurately classifying emotions in text samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc51e94",
   "metadata": {},
   "source": [
    "#### 2. Feature Extraction (2 marks):\n",
    "Implement feature extraction using CountVectorizer or TfidfVectorizer. Describe how the chosen method transforms the text data into numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b56495",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the processed comments into TF-IDF features\n",
    "X = vectorizer.fit_transform(data['processed_comment'])\n",
    "y = data['Emotion']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07cf5d",
   "metadata": {},
   "source": [
    "### TF-IDF transforms the text into numerical features by calculating the importance of each word relative to its frequency across documents. This helps in emphasizing unique words associated with specific emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa0ad29",
   "metadata": {},
   "source": [
    "#### 3. Model Development (2 marks):\n",
    "Train the following machine learning models\n",
    "\n",
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "add7716c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.91, F1 Score: 0.91\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
    "nb_f1_score = f1_score(y_test, nb_predictions, average='weighted')\n",
    "\n",
    "print(f'Naive Bayes Accuracy: {nb_accuracy:.2f}, F1 Score: {nb_f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fbc3e",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338caf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.95, F1 Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "svm_predictions = svm_model.predict(X_test)\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "svm_f1_score = f1_score(y_test, svm_predictions, average='weighted')\n",
    "\n",
    "print(f'SVM Accuracy: {svm_accuracy:.2f}, F1 Score: {svm_f1_score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadf3b9",
   "metadata": {},
   "source": [
    "### 4. Model Comparison (2 marks)\n",
    "Evaluate the model using appropriate metrics (e.g., accuracy, F1-score). Provide a brief explanation of the chosen model and its suitability for emotion classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9e191a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "Naive Bayes - Accuracy: 0.91, F1 Score: 0.91\n",
      "SVM - Accuracy: 0.95, F1 Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Print comparison results\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(f\"Naive Bayes - Accuracy: {nb_accuracy:.2f}, F1 Score: {nb_f1_score:.2f}\")\n",
    "print(f\"SVM - Accuracy: {svm_accuracy:.2f}, F1 Score: {svm_f1_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d746b9f1",
   "metadata": {},
   "source": [
    "### Model Comparison\n",
    "After training our models, we evaluated their performance using two key metrics: accuracy and F1 score.\n",
    "\n",
    "#### Naive Bayes\n",
    "\n",
    "#### Accuracy: 0.91\n",
    "#### F1 Score: 0.91\n",
    "#### Support Vector Machine (SVM)\n",
    "\n",
    "#### Accuracy: 0.95\n",
    "#### F1 Score: 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784c733a",
   "metadata": {},
   "source": [
    "### Explanation of Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a173ad29",
   "metadata": {},
   "source": [
    "#### Accuracy: \n",
    "This tells us how many predictions the model got right out of all predictions made. For example, an accuracy of 0.95 means that the SVM model correctly identified emotions in 95 out of every 100 text samples. A higher accuracy indicates a better-performing model.\n",
    "\n",
    "#### F1 Score: \n",
    "This is a measure that combines two important aspects of model performance: precision and recall.\n",
    "\n",
    "Precision is how many of the predicted positive cases were actually positive (correctly identified emotions).\n",
    "Recall is how many actual positive cases were correctly identified by the model.\n",
    "The F1 score gives us a single number that balances both precision and recall, making it useful when we want to ensure that our model is not just good at guessing but also good at capturing all relevant cases. An F1 score of 0.95 for the SVM means it has a strong ability to identify emotions accurately without missing too many.\n",
    "\n",
    "## Conclusion\n",
    "In this comparison, the SVM model outperformed the Naive Bayes model in both accuracy and F1 score, suggesting it is better at understanding and classifying emotions in text data. This means that for tasks like identifying feelings expressed in writing, SVM may be a more reliable choice than Naive Bayes based on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2609028",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
